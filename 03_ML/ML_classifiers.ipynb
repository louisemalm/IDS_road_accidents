{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers for accident fatality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for training a Random Forest model\n",
    "\n",
    "#### First, train three basic RF models (using default settings) with the different training data (original, oversampled and undersampled)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
    "from joblib import load\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data with no resampling\n",
    "X_train_orig = pd.read_csv('../00_data/X_train_orig_road_acc.csv')\n",
    "y_train_orig = pd.read_csv('../00_data/y_train_orig_road_acc.csv')\n",
    "\n",
    "# Oversampled training data\n",
    "X_train_oversamp = pd.read_csv('../00_data/X_train_oversamp_road_acc.csv')\n",
    "y_train_oversamp = pd.read_csv('../00_data/y_train_oversamp_road_acc.csv')\n",
    "\n",
    "# Undersampled training data\n",
    "X_train_undersamp = pd.read_csv('../00_data/X_train_undersamp_road_acc.csv')\n",
    "y_train_undersamp = pd.read_csv('../00_data/y_train_undersamp_road_acc.csv')\n",
    "\n",
    "# Ensemble resampled training data\n",
    "X_train_ensemble = pd.read_csv('../00_data/X_train_ensemble_road_acc.csv')\n",
    "y_train_ensemble = pd.read_csv('../00_data/y_train_ensemble_road_acc.csv')\n",
    "\n",
    "\n",
    "# Validation data\n",
    "X_val = pd.read_csv('../00_data/X_val_road_acc.csv')\n",
    "y_val = pd.read_csv('../00_data/y_val_road_acc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF model trained on original (unbalanced) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF model (default values) trained on original (unbalanced) data\n",
      "Cross-validation scores for each fold: [0.98997223 0.9899275  0.98999442 0.98987172 0.99022867]\n",
      "Average cross-validation score: 0.989998906921973\n",
      "AUC Score: 0.585031640849742\n",
      "Validation Accuracy: 0.9900368542694734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     95168\n",
      "           1       0.00      0.00      0.00       886\n",
      "\n",
      "    accuracy                           0.99     96054\n",
      "   macro avg       0.50      0.50      0.50     96054\n",
      "weighted avg       0.98      0.99      0.99     96054\n",
      "\n",
      "Confusion Matrix:\n",
      "[[95097    71]\n",
      " [  886     0]]\n"
     ]
    }
   ],
   "source": [
    "rf_clf_orig = RandomForestClassifier(random_state = 33)\n",
    "\n",
    "# 5-fold cross-validation\n",
    "cv_scores_orig = cross_val_score(rf_clf_orig, X_train_orig, y_train_orig.values.ravel(), cv = 5)\n",
    "\n",
    "# Print the cross-validation scores for each fold and the mean CV score\n",
    "print(\"RF model (default values) trained on original (unbalanced) data\")\n",
    "print(\"Cross-validation scores for each fold:\", cv_scores_orig)\n",
    "print(\"Average cross-validation score:\", cv_scores_orig.mean())\n",
    "\n",
    "# Fit the model to original training data\n",
    "rf_clf_orig.fit(X_train_orig, y_train_orig.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set\n",
    "prob_predictions = rf_clf_orig.predict_proba(X_val)[:, 1]  # probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = rf_clf_orig.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, this model did not perform well. It basically predicts everyting as non-fatal and has zero true positives, i.e., zero instances of correctly classified fatal accidents. Area under the curve is 58.5%, meaning it is only slightly better than random guesser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF model trained on oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF model (default values) trained on oversampled data\n",
      "Cross-validation scores for each fold: [0.95264124 0.97006918 0.9691685  0.96983838 0.97039568]\n",
      "Average cross-validation score: 0.9664225974102694\n",
      "AUC Score: 0.5879311408523987\n",
      "Validation Accuracy: 0.9551502279967519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98     95168\n",
      "           1       0.03      0.13      0.05       886\n",
      "\n",
      "    accuracy                           0.96     96054\n",
      "   macro avg       0.51      0.55      0.51     96054\n",
      "weighted avg       0.98      0.96      0.97     96054\n",
      "\n",
      "Confusion Matrix:\n",
      "[[91630  3538]\n",
      " [  770   116]]\n"
     ]
    }
   ],
   "source": [
    "rf_clf_oversamp = RandomForestClassifier(random_state = 33)\n",
    "\n",
    "# 5-fold cross-validation\n",
    "cv_scores_oversamp = cross_val_score(rf_clf_oversamp, X_train_oversamp, y_train_oversamp.values.ravel(), cv = 5)\n",
    "\n",
    "# Print the cross-validation scores for each fold\n",
    "print(\"RF model (default values) trained on oversampled data\")\n",
    "print(\"Cross-validation scores for each fold:\", cv_scores_oversamp)\n",
    "\n",
    "# Print the average cross-validation score\n",
    "print(\"Average cross-validation score:\", cv_scores_oversamp.mean())\n",
    "\n",
    "# Fit the model to original training data\n",
    "rf_clf_oversamp.fit(X_train_oversamp, y_train_oversamp.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set\n",
    "prob_predictions = rf_clf_oversamp.predict_proba(X_val)[:, 1]  # probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = rf_clf_oversamp.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using oversampled training data slightly improved the model, however, it still performs quite badly. Now, we have 116 true positives, and almost the same area under the curve (58.8%) as the previous code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF model trained on undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF model (default values) trained on undersampled data\n",
      "Cross-validation scores for each fold: [0.6562123  0.67410984 0.65117683 0.67229934 0.65238383]\n",
      "Average cross-validation score: 0.6612364257931224\n",
      "AUC Score: 0.6840373696756388\n",
      "Validation Accuracy: 0.6697586774106232\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.67      0.80     95168\n",
      "           1       0.02      0.62      0.03       886\n",
      "\n",
      "    accuracy                           0.67     96054\n",
      "   macro avg       0.51      0.64      0.42     96054\n",
      "weighted avg       0.99      0.67      0.79     96054\n",
      "\n",
      "Confusion Matrix:\n",
      "[[63784 31384]\n",
      " [  337   549]]\n"
     ]
    }
   ],
   "source": [
    "rf_clf_undersamp = RandomForestClassifier(random_state = 33)\n",
    "\n",
    "# 5-fold cross-validation\n",
    "cv_scores_undersamp = cross_val_score(rf_clf_undersamp, X_train_undersamp, y_train_undersamp.values.ravel(), cv = 5)\n",
    "\n",
    "# Print the cross-validation scores for each fold\n",
    "print(\"RF model (default values) trained on undersampled data\")\n",
    "print(\"Cross-validation scores for each fold:\", cv_scores_undersamp)\n",
    "\n",
    "# Print the average cross-validation score\n",
    "print(\"Average cross-validation score:\", cv_scores_undersamp.mean())\n",
    "\n",
    "# Fit the model to original training data\n",
    "rf_clf_undersamp.fit(X_train_undersamp, y_train_undersamp.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set\n",
    "prob_predictions = rf_clf_undersamp.predict_proba(X_val)[:, 1]  # probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = rf_clf_undersamp.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel() class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using undersampled data improved the results further, increasing the number of true positives to 549 and the area under the curve increased 68.4%. However, also the number of false positives (non-fatal accidents predicted as fatal) also drastically increased. </br> </br>\n",
    "None of the models yielded particularly good results, thus we will test some parameter tuning. We will focus on oversampled and undersampled training data only for the parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning\n",
    "\n",
    "#### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the hyperparameter search on a subset of the whole dataset\n",
    "\n",
    "subset_size = 0.1 \n",
    "X_train_oversamp_subset = X_train_oversamp.sample(frac = subset_size, random_state = 33)\n",
    "y_train_oversamp_subset = y_train_oversamp.loc[X_train_oversamp_subset.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "# Define a parameter distribution to sample from\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [None, 10, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Initialize the base model\n",
    "rf_clf = RandomForestClassifier(random_state = 33)\n",
    "\n",
    "# Set up the RandomizedSearchCV object\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    estimator = rf_clf,\n",
    "    param_distributions = param_distributions,\n",
    "    n_iter = 100,\n",
    "    cv = 5, \n",
    "    verbose = 2,\n",
    "    random_state = 33,\n",
    "    n_jobs = 12\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "rf_random_search.fit(X_train_oversamp_subset, y_train_oversamp_subset.values.ravel())\n",
    "\n",
    "# Get the best estimator\n",
    "best_rf_clf = rf_random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.6049742045811632\n",
      "Validation Accuracy: 0.9559726820330231\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98     95168\n",
      "           1       0.03      0.13      0.05       886\n",
      "\n",
      "    accuracy                           0.96     96054\n",
      "   macro avg       0.51      0.55      0.51     96054\n",
      "weighted avg       0.98      0.96      0.97     96054\n",
      "\n",
      "Confusion Matrix:\n",
      " [[91711  3457]\n",
      " [  772   114]]\n",
      "Best Hyperparameters:\n",
      " {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy', 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "# Fit the model with the best hyperparameters on the full oversampled training data\n",
    "best_rf_clf.fit(X_train_oversamp, y_train_oversamp.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set for AUC calculation\n",
    "prob_predictions = best_rf_clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = best_rf_clf.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\\n\", rf_random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "AUC Score: 0.736727463354338\n",
      "Validation Accuracy: 0.7450288379453224\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.85     95168\n",
      "           1       0.02      0.61      0.04       886\n",
      "\n",
      "    accuracy                           0.75     96054\n",
      "   macro avg       0.51      0.68      0.45     96054\n",
      "weighted avg       0.99      0.75      0.85     96054\n",
      "\n",
      "Confusion Matrix:\n",
      " [[71021 24147]\n",
      " [  344   542]]\n",
      "Best Hyperparameters:\n",
      " {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'entropy', 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [None, 10, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Initialize the base model\n",
    "rf_clf = RandomForestClassifier(random_state = 33)\n",
    "\n",
    "# Set up the RandomizedSearchCV object\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    estimator = rf_clf,\n",
    "    param_distributions = param_distributions,\n",
    "    n_iter = 100,\n",
    "    cv = 5, \n",
    "    verbose = 2,\n",
    "    random_state = 33,\n",
    "    n_jobs = 12\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "rf_random_search.fit(X_train_undersamp, y_train_undersamp.values.ravel())\n",
    "\n",
    "# Get the best estimator\n",
    "best_rf_clf = rf_random_search.best_estimator_\n",
    "\n",
    "# Fit the model with the best hyperparameters on the full oversampled training data\n",
    "best_rf_clf.fit(X_train_undersamp, y_train_undersamp.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set for AUC calculation\n",
    "prob_predictions = best_rf_clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = best_rf_clf.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\\n\", rf_random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter tuning did not really improve the results. The AUC scores were improved, especially for the undersampled data, but the number of true positves remained more or less the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance of tunes models\n",
    "\n",
    "#### Oversampled\n",
    "\n",
    "Below comes the feature importance analysis from the tuned random forest classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.6049742342305247\n",
      "Validation Accuracy: 0.9559726820330231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98     95168\n",
      "           1       0.03      0.13      0.05       886\n",
      "\n",
      "    accuracy                           0.96     96054\n",
      "   macro avg       0.51      0.55      0.51     96054\n",
      "weighted avg       0.98      0.96      0.97     96054\n",
      "\n",
      "Confusion Matrix:\n",
      "[[91711  3457]\n",
      " [  772   114]]\n"
     ]
    }
   ],
   "source": [
    "# Retraining the model (in case not done at the same time as parameter tuning)\n",
    "\n",
    "best_rf_clf_over = RandomForestClassifier(n_estimators = 100,\n",
    "                                          criterion = 'entropy',\n",
    "                                          max_depth = None,\n",
    "                                          min_samples_split = 10,\n",
    "                                          min_samples_leaf = 1,\n",
    "                                          max_features = 'sqrt',\n",
    "                                          bootstrap = False,\n",
    "                                          n_jobs = 12,\n",
    "                                          random_state = 33)\n",
    "\n",
    "# Fit the model to oversampled training data\n",
    "best_rf_clf_over.fit(X_train_oversamp, y_train_oversamp.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set\n",
    "prob_predictions = best_rf_clf_over.predict_proba(X_val)[:, 1]  # probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = best_rf_clf_over.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          feature  importance\n",
      "69                         speed_limit_bins_30-39    0.042290\n",
      "20                     junction_detail_roundabout    0.037156\n",
      "75                       time_of_day_evening_rush    0.035745\n",
      "0                              day_of_week_friday    0.034288\n",
      "6                           day_of_week_wednesday    0.033062\n",
      "..                                            ...         ...\n",
      "63  carriageway_hazards_pedestrian_in_carriageway    0.000102\n",
      "41          weather_conditions_snowing_high_winds    0.000094\n",
      "47     road_surface_conditions_oil_or_diesel_road    0.000031\n",
      "46               road_surface_conditions_mud_road    0.000008\n",
      "59                carriageway_hazards_dog_on_road    0.000007\n",
      "\n",
      "[79 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the encoder\n",
    "encoder = load('../00_data/encoder.joblib')\n",
    "\n",
    "# Get feature importances\n",
    "importances = best_rf_clf_over.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = encoder.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(feature_importances_df)\n",
    "\n",
    "feature_importances_df.to_csv('../00_data/feature_importance_RF_oversampled.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.736727463354338\n",
      "Validation Accuracy: 0.7450288379453224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.85     95168\n",
      "           1       0.02      0.61      0.04       886\n",
      "\n",
      "    accuracy                           0.75     96054\n",
      "   macro avg       0.51      0.68      0.45     96054\n",
      "weighted avg       0.99      0.75      0.85     96054\n",
      "\n",
      "Confusion Matrix:\n",
      "[[71021 24147]\n",
      " [  344   542]]\n"
     ]
    }
   ],
   "source": [
    "# Retraining the model (in case not done at the same time as parameter tuning)\n",
    "\n",
    "best_rf_clf_under = RandomForestClassifier(n_estimators = 100,\n",
    "                                          criterion = 'entropy',\n",
    "                                          max_depth = 10,\n",
    "                                          min_samples_split = 10,\n",
    "                                          min_samples_leaf = 4,\n",
    "                                          max_features = 'log2',\n",
    "                                          bootstrap = False,\n",
    "                                          n_jobs = 12,\n",
    "                                          random_state = 33)\n",
    "\n",
    "# Fit the model to oversampled training data\n",
    "best_rf_clf_under.fit(X_train_undersamp, y_train_undersamp.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set\n",
    "prob_predictions = best_rf_clf_under.predict_proba(X_val)[:, 1]  # probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = best_rf_clf_under.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          feature  importance\n",
      "66                      urban_or_rural_area_rural    0.102950\n",
      "20                     junction_detail_roundabout    0.102151\n",
      "69                         speed_limit_bins_30-39    0.074415\n",
      "67                      urban_or_rural_area_urban    0.069410\n",
      "72                         speed_limit_bins_60-69    0.060589\n",
      "..                                            ...         ...\n",
      "59                carriageway_hazards_dog_on_road    0.000000\n",
      "41          weather_conditions_snowing_high_winds    0.000000\n",
      "63  carriageway_hazards_pedestrian_in_carriageway    0.000000\n",
      "47     road_surface_conditions_oil_or_diesel_road    0.000000\n",
      "46               road_surface_conditions_mud_road    0.000000\n",
      "\n",
      "[79 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the encoder\n",
    "encoder = load('../00_data/encoder.joblib')\n",
    "\n",
    "# Get feature importances\n",
    "importances = best_rf_clf_under.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = encoder.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(feature_importances_df)\n",
    "\n",
    "feature_importances_df.to_csv('../00_data/feature_importance_RF_undersampled.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for training an XGBoost model\n",
    "\n",
    "#### First, train three basic XGB models (using default settings) with the different training data (original, oversampled and undersampled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from XGBoost trained on unbalanced (original) data\n",
      "Validation Accuracy: 0.990776021821059\n",
      "Validation ROC AUC Score: 0.7308531480411118\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     95168\n",
      "           1       0.00      0.00      0.00       886\n",
      "\n",
      "    accuracy                           0.99     96054\n",
      "   macro avg       0.50      0.50      0.50     96054\n",
      "weighted avg       0.98      0.99      0.99     96054\n",
      "\n",
      "Validation Confusion Matrix:\n",
      "[[95168     0]\n",
      " [  886     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loma5202\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\loma5202\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\loma5202\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Unbalanced (original) data\n",
    "\n",
    "# Instantiate an XGBoost classifier object\n",
    "xgb_clf_orig = xgb.XGBClassifier(use_label_encoder = False, eval_metric = 'logloss', random_state = 33)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "xgb_clf_orig.fit(X_train_orig, y_train_orig.values.ravel())\n",
    "\n",
    "# Predict the labels for the validation set\n",
    "y_val_pred = xgb_clf_orig.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), y_val_pred)\n",
    "\n",
    "# Calculate the ROC AUC score\n",
    "val_roc_auc = roc_auc_score(y_val.values.ravel(), xgb_clf_orig.predict_proba(X_val)[:,1])\n",
    "\n",
    "# Generate a confusion matrix\n",
    "val_conf_matrix = confusion_matrix(y_val.values.ravel(), y_val_pred)\n",
    "\n",
    "# Generate a classification report\n",
    "val_class_report = classification_report(y_val.values.ravel(), y_val_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Results from XGBoost trained on unbalanced (original) data\")\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print(f'Validation ROC AUC Score: {val_roc_auc}')\n",
    "print('Validation Classification Report:')\n",
    "print(val_class_report)\n",
    "print('Validation Confusion Matrix:')\n",
    "print(val_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted everything as non-fatal, so using the unbalanced data here is useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from XGBoost trained on oversampled (SMOTE) data\n",
      "Validation Accuracy: 0.9583359360359798\n",
      "Validation ROC AUC Score: 0.6752880625219168\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     95168\n",
      "           1       0.04      0.15      0.06       886\n",
      "\n",
      "    accuracy                           0.96     96054\n",
      "   macro avg       0.52      0.56      0.52     96054\n",
      "weighted avg       0.98      0.96      0.97     96054\n",
      "\n",
      "Validation Confusion Matrix:\n",
      "[[91915  3253]\n",
      " [  749   137]]\n"
     ]
    }
   ],
   "source": [
    "# SMOTE oversampled data\n",
    "\n",
    "# Instantiate an XGBoost classifier object\n",
    "xgb_clf_over = xgb.XGBClassifier(use_label_encoder = False, eval_metric = 'logloss', random_state = 33)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "xgb_clf_over.fit(X_train_oversamp, y_train_oversamp.values.ravel())\n",
    "\n",
    "# Predict the labels for the validation set\n",
    "y_val_pred = xgb_clf_over.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), y_val_pred)\n",
    "\n",
    "# Calculate the ROC AUC score\n",
    "val_roc_auc = roc_auc_score(y_val.values.ravel(), xgb_clf_over.predict_proba(X_val)[:,1])\n",
    "\n",
    "# Generate a confusion matrix\n",
    "val_conf_matrix = confusion_matrix(y_val.values.ravel(), y_val_pred)\n",
    "\n",
    "# Generate a classification report\n",
    "val_class_report = classification_report(y_val.values.ravel(), y_val_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Results from XGBoost trained on oversampled (SMOTE) data\")\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print(f'Validation ROC AUC Score: {val_roc_auc}')\n",
    "print('Validation Classification Report:')\n",
    "print(val_class_report)\n",
    "print('Validation Confusion Matrix:')\n",
    "print(val_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better but still pretty bad... Only correctly predicts 137 fatal accidents. Better AUC score compared to random forest classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from XGBoost trained on undersampled (randomised) data\n",
      "Validation Accuracy: 0.7140150332104858\n",
      "Validation ROC AUC Score: 0.7191545477471419\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.71      0.83     95168\n",
      "           1       0.02      0.63      0.04       886\n",
      "\n",
      "    accuracy                           0.71     96054\n",
      "   macro avg       0.51      0.67      0.44     96054\n",
      "weighted avg       0.99      0.71      0.82     96054\n",
      "\n",
      "Validation Confusion Matrix:\n",
      "[[68024 27144]\n",
      " [  326   560]]\n"
     ]
    }
   ],
   "source": [
    "# Randomised undersampled data\n",
    "\n",
    "# Instantiate an XGBoost classifier object\n",
    "xgb_clf_under = xgb.XGBClassifier(use_label_encoder = False, eval_metric = 'logloss', random_state = 33)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "xgb_clf_under.fit(X_train_undersamp, y_train_undersamp.values.ravel())\n",
    "\n",
    "# Predict the labels for the validation set\n",
    "y_val_pred = xgb_clf_under.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), y_val_pred)\n",
    "\n",
    "# Calculate the ROC AUC score\n",
    "val_roc_auc = roc_auc_score(y_val.values.ravel(), xgb_clf_under.predict_proba(X_val)[:,1])\n",
    "\n",
    "# Generate a confusion matrix\n",
    "val_conf_matrix = confusion_matrix(y_val.values.ravel(), y_val_pred)\n",
    "\n",
    "# Generate a classification report\n",
    "val_class_report = classification_report(y_val.values.ravel(), y_val_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Results from XGBoost trained on undersampled (randomised) data\")\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print(f'Validation ROC AUC Score: {val_roc_auc}')\n",
    "print('Validation Classification Report:')\n",
    "print(val_class_report)\n",
    "print('Validation Confusion Matrix:')\n",
    "print(val_conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even better but may be improved with hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform randomised hyperparameter search to see if XGB models can be improved. Only train with over- and undersampled data.\n",
    "\n",
    "#### Oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the hyperparameter search on a subset of the whole dataset\n",
    "\n",
    "subset_size = 0.1 \n",
    "X_train_oversamp_subset = X_train_oversamp.sample(frac = subset_size, random_state = 33)\n",
    "y_train_oversamp_subset = y_train_oversamp.loc[X_train_oversamp_subset.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'subsample': 0.7, 'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 10, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "Validation ROC AUC Score: 0.6476119431802484\n",
      "Validation Accuracy: 0.9580444333395798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     95168\n",
      "           1       0.03      0.13      0.05       886\n",
      "\n",
      "    accuracy                           0.96     96054\n",
      "   macro avg       0.51      0.55      0.52     96054\n",
      "weighted avg       0.98      0.96      0.97     96054\n",
      "\n",
      "[[91911  3257]\n",
      " [  773   113]]\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter grid to search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'subsample': [0.5, 0.7, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb = XGBClassifier(use_label_encoder = False, eval_metric = 'logloss')\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator = xgb,\n",
    "    param_distributions = param_grid,\n",
    "    n_iter = 100,  # Number of parameter settings sampled. Adjust according to your computational resources\n",
    "    scoring = 'roc_auc',  # Can change to 'accuracy' or other metrics\n",
    "    cv = 5,\n",
    "    verbose = 2,\n",
    "    random_state = 33,\n",
    "    n_jobs = -1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "random_search.fit(X_train_oversamp_subset, y_train_oversamp_subset.values.ravel())\n",
    "\n",
    "# Get the best estimator\n",
    "best_xgb_over = random_search.best_estimator_\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "\n",
    "# Train the best estimator on the full training data\n",
    "best_xgb_over.fit(X_train_oversamp, y_train_oversamp.values.ravel())\n",
    "\n",
    "# Predict probabilities on the validation set\n",
    "y_val_pred_prob = best_xgb_over.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Compute the ROC AUC score\n",
    "val_roc_auc = roc_auc_score(y_val.values.ravel(), y_val_pred_prob)\n",
    "print(f\"Validation ROC AUC Score: {val_roc_auc}\")\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_xgb_over.predict(X_val)\n",
    "\n",
    "# Compute accuracy\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_val.values.ravel(), y_val_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_val.values.ravel(), y_val_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance of oversampled XGB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            feature  importance\n",
      "67        urban_or_rural_area_urban    0.111699\n",
      "20       junction_detail_roundabout    0.078333\n",
      "68           speed_limit_bins_20-29    0.046826\n",
      "69           speed_limit_bins_30-39    0.037532\n",
      "26  junction_control_not_a_junction    0.037153\n"
     ]
    }
   ],
   "source": [
    "# Load the encoder\n",
    "encoder = load('../00_data/encoder.joblib')\n",
    "\n",
    "# Get feature importances\n",
    "importances = best_xgb_over.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = encoder.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(feature_importances_df.head())  # Adjust the number of rows to display as needed\n",
    "\n",
    "feature_importances_df.to_csv('../00_data/feature_importance_XGB_oversampled.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'subsample': 1.0, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "Validation ROC AUC Score: 0.7379815661143757\n",
      "Validation Accuracy: 0.7305786328523539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.73      0.84     95168\n",
      "           1       0.02      0.64      0.04       886\n",
      "\n",
      "    accuracy                           0.73     96054\n",
      "   macro avg       0.51      0.69      0.44     96054\n",
      "weighted avg       0.99      0.73      0.84     96054\n",
      "\n",
      "[[69606 25562]\n",
      " [  317   569]]\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter grid to search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'subsample': [0.5, 0.7, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb = XGBClassifier(use_label_encoder = False, eval_metric = 'logloss')\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator = xgb,\n",
    "    param_distributions = param_grid,\n",
    "    n_iter = 100,  # Number of parameter settings sampled. Adjust according to your computational resources\n",
    "    scoring = 'roc_auc',  # Can change to 'accuracy' or other metrics\n",
    "    cv = 5,\n",
    "    verbose = 2,\n",
    "    random_state = 33,\n",
    "    n_jobs = -1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "random_search.fit(X_train_undersamp, y_train_undersamp.values.ravel())\n",
    "\n",
    "# Get the best estimator\n",
    "best_xgb_under = random_search.best_estimator_\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "\n",
    "# Train the best estimator on the full training data\n",
    "best_xgb_under.fit(X_train_undersamp, y_train_undersamp.values.ravel())\n",
    "\n",
    "# Predict probabilities on the validation set\n",
    "y_val_pred_prob = best_xgb_under.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Compute the ROC AUC score\n",
    "val_roc_auc = roc_auc_score(y_val.values.ravel(), y_val_pred_prob)\n",
    "print(f\"Validation ROC AUC Score: {val_roc_auc}\")\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_xgb_under.predict(X_val)\n",
    "\n",
    "# Compute accuracy\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_val.values.ravel(), y_val_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_val.values.ravel(), y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            feature  importance\n",
      "67        urban_or_rural_area_urban    0.119632\n",
      "20       junction_detail_roundabout    0.108156\n",
      "26  junction_control_not_a_junction    0.072534\n",
      "69           speed_limit_bins_30-39    0.071924\n",
      "66        urban_or_rural_area_rural    0.069595\n"
     ]
    }
   ],
   "source": [
    "# Load the encoder\n",
    "encoder = load('../00_data/encoder.joblib')\n",
    "\n",
    "# Get feature importances\n",
    "importances = best_xgb_under.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = encoder.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(feature_importances_df.head())  # Adjust the number of rows to display as needed\n",
    "\n",
    "feature_importances_df.to_csv('../00_data/feature_importance_XGB_undersampled.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble resampled\n",
    "\n",
    "Since XGBoost model seems better than Random Forest, we will train it also using a combination of under- and oversampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'subsample': 0.7, 'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 10, 'learning_rate': 0.01, 'colsample_bytree': 0.7}\n",
      "Validation ROC AUC Score: 0.7357696525929766\n",
      "Validation Accuracy: 0.8302621442105482\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.91     95168\n",
      "           1       0.03      0.51      0.05       886\n",
      "\n",
      "    accuracy                           0.83     96054\n",
      "   macro avg       0.51      0.67      0.48     96054\n",
      "weighted avg       0.99      0.83      0.90     96054\n",
      "\n",
      "[[79295 15873]\n",
      " [  431   455]]\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter grid to search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'subsample': [0.5, 0.7, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb = XGBClassifier(use_label_encoder = False, eval_metric = 'logloss')\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator = xgb,\n",
    "    param_distributions = param_grid,\n",
    "    n_iter = 100,  # Number of parameter settings sampled. Adjust according to your computational resources\n",
    "    scoring = 'roc_auc',  # Can change to 'accuracy' or other metrics\n",
    "    cv = 5,\n",
    "    verbose = 2,\n",
    "    random_state = 33,\n",
    "    n_jobs = -1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "random_search.fit(X_train_ensemble, y_train_ensemble.values.ravel())\n",
    "\n",
    "# Get the best estimator\n",
    "best_xgb_ensemble = random_search.best_estimator_\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "\n",
    "# Train the best estimator on the full training data\n",
    "best_xgb_ensemble.fit(X_train_ensemble, y_train_ensemble.values.ravel())\n",
    "\n",
    "# Predict probabilities on the validation set\n",
    "y_val_pred_prob = best_xgb_ensemble.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Compute the ROC AUC score\n",
    "val_roc_auc = roc_auc_score(y_val.values.ravel(), y_val_pred_prob)\n",
    "print(f\"Validation ROC AUC Score: {val_roc_auc}\")\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_xgb_ensemble.predict(X_val)\n",
    "\n",
    "# Compute accuracy\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_val.values.ravel(), y_val_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_val.values.ravel(), y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using combined under- and oversampled training data did not improve the model. </br></br>\n",
    "Since we were more interested in correctly classifying fatal accidents, we decided that the true positives, that is, correctly identified fatal accidents, outweight the high number of false positives (non-fatal accidents predicted as fatal). </br>\n",
    "Thus, based on the number of true positives together with the AUC score, XGBoost classifier trained on undersampled data was deemed the best performing model, and will be tested using the test data. </br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data\n",
    "X_test = pd.read_csv('../00_data/X_test_road_acc.csv')\n",
    "y_test = pd.read_csv('../00_data/y_test_road_acc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC Score: 0.7485831427594654\n",
      "Test Accuracy: 0.7301309679971683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.73      0.84     95142\n",
      "           1       0.02      0.65      0.04       912\n",
      "\n",
      "    accuracy                           0.73     96054\n",
      "   macro avg       0.51      0.69      0.44     96054\n",
      "weighted avg       0.99      0.73      0.84     96054\n",
      "\n",
      "[[69536 25606]\n",
      " [  316   596]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the XGBClassifier\n",
    "best_xgb = XGBClassifier(use_label_encoder = False, \n",
    "                    eval_metric = 'logloss',\n",
    "                    max_depth = 3,\n",
    "                    min_child_weight = 1,\n",
    "                    subsample = 1.0,\n",
    "                    colsample_bytree = 0.5,\n",
    "                    n_estimators = 200,\n",
    "                    learning_rate = 0.1)\n",
    "\n",
    "\n",
    "# Train the best estimator on the full training data\n",
    "best_xgb.fit(X_train_undersamp, y_train_undersamp.values.ravel())\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "y_test_pred_prob = best_xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute the ROC AUC score\n",
    "test_roc_auc = roc_auc_score(y_test.values.ravel(), y_test_pred_prob)\n",
    "print(f\"Test ROC AUC Score: {test_roc_auc}\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = best_xgb.predict(X_test)\n",
    "\n",
    "# Compute accuracy\n",
    "test_accuracy = accuracy_score(y_test.values.ravel(), y_test_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test.values.ravel(), y_test_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test.values.ravel(), y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
